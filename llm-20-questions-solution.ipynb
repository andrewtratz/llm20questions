{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":61247,"databundleVersionId":8550470,"sourceType":"competition"},{"sourceId":9035068,"sourceType":"datasetVersion","datasetId":5446214},{"sourceId":9063357,"sourceType":"datasetVersion","datasetId":5465816},{"sourceId":9150113,"sourceType":"datasetVersion","datasetId":5491039}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Full project write-up at: https://www.kaggle.com/competitions/llm-20-questions/discussion/529643**","metadata":{}},{"cell_type":"code","source":"########## Requirements for Kaggle dataset to run:\n\n# Add the following datasets:\n#   https://www.kaggle.com/datasets/jademonk/frequencies\n#   https://www.kaggle.com/datasets/canming/llama-3-1-8b-instruct\n#   https://www.kaggle.com/datasets/jademonk/frequencies\n\n# Enable GPU and Internet for the notebook","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%bash\nmkdir -p /kaggle/tmp/\nmkdir -p /kaggle/working/submission\n","metadata":{"execution":{"iopub.status.busy":"2024-07-25T23:12:31.103703Z","iopub.execute_input":"2024-07-25T23:12:31.104074Z","iopub.status.idle":"2024-07-25T23:12:31.117693Z","shell.execute_reply.started":"2024-07-25T23:12:31.104046Z","shell.execute_reply":"2024-07-25T23:12:31.116245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nnp.__version__","metadata":{"execution":{"iopub.status.busy":"2024-07-23T14:11:39.685282Z","iopub.execute_input":"2024-07-23T14:11:39.685991Z","iopub.status.idle":"2024-07-23T14:11:39.718041Z","shell.execute_reply.started":"2024-07-23T14:11:39.685934Z","shell.execute_reply":"2024-07-23T14:11:39.716245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from importlib.metadata import version\nversion('numpy')","metadata":{"execution":{"iopub.status.busy":"2024-07-23T14:11:42.628973Z","iopub.execute_input":"2024-07-23T14:11:42.629641Z","iopub.status.idle":"2024-07-23T14:11:42.677715Z","shell.execute_reply.started":"2024-07-23T14:11:42.629607Z","shell.execute_reply":"2024-07-23T14:11:42.676745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install dependencies to tmp directory for packaging in solution\n\nimport os, sys\nos.system(\"pip install --no-dependencies -U -t /kaggle/tmp/lib bitsandbytes\")\nsys.path.insert(0, \"/kaggle/working/submission/lib\")\nsys.path.insert(0, \"/kaggle/tmp/lib\")\n\nimport numpy as np\nnp.__version__\n\n!pip freeze > modified_requirements.txt","metadata":{"execution":{"iopub.status.busy":"2024-07-23T14:11:50.035637Z","iopub.execute_input":"2024-07-23T14:11:50.036022Z","iopub.status.idle":"2024-07-23T14:12:01.066599Z","shell.execute_reply.started":"2024-07-23T14:11:50.035991Z","shell.execute_reply":"2024-07-23T14:12:01.065334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set up Llama 3.1\n\nimport shutil\nsrc_path = r\"/kaggle/input/llama-3-1-8b-instruct\"\ndst_path = r\"/kaggle/tmp/llama-3-1/\"\nshutil.copytree(src_path, dst_path)\n\n# Fix bug preventing Llama 3.1 from working on Kaggle\n\nimport json\nwith open(os.path.join(\"/kaggle/tmp/llama-3-1/\", \"config.json\"), \"r\") as file:\n    config = json.load(file)\nconfig[\"rope_scaling\"] = {\"factor\":8.0,\"type\":\"dynamic\"}\nwith open(os.path.join(\"/kaggle/tmp/llama-3-1/\", \"config.json\"), \"w\") as file:\n    json.dump(config, file)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Copy keyword lists into working and submission directories\n\nimport shutil\nsrc_path = r\"/kaggle/input/keyword-list/keywords.txt\"\ndst_path = r\"/kaggle/working/keywords.txt\"\nshutil.copy(src_path, dst_path)\ndst_path = r\"/kaggle/working/submission/keywords.txt\"\nshutil.copy(src_path, dst_path)\n\n# src_path = r\"/kaggle/input/kw-kats/kw_cats_for_test.csv\"\n# dst_path = r\"/kaggle/working/kw_cats_for_test.csv\"\n# shutil.copy(src_path, dst_path)\n# dst_path = r\"/kaggle/working/submission/kw_cats_for_test.csv\"\n# shutil.copy(src_path, dst_path)\n\nsrc_path = r\"/kaggle/input/frequencies/my_freq.csv\"\ndst_path = r\"/kaggle/working/my_freq.csv\"\nshutil.copy(src_path, dst_path)\ndst_path = r\"/kaggle/working/submission/my_freq.csv\"\nshutil.copy(src_path, dst_path)","metadata":{"execution":{"iopub.status.busy":"2024-07-25T23:12:37.763224Z","iopub.execute_input":"2024-07-25T23:12:37.763648Z","iopub.status.idle":"2024-07-25T23:12:37.782886Z","shell.execute_reply.started":"2024-07-25T23:12:37.763614Z","shell.execute_reply":"2024-07-25T23:12:37.781607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import importlib\nfrom importlib.metadata import version \nversion(\"numpy\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-23T14:12:03.340687Z","iopub.execute_input":"2024-07-23T14:12:03.341422Z","iopub.status.idle":"2024-07-23T14:12:03.358069Z","shell.execute_reply.started":"2024-07-23T14:12:03.341384Z","shell.execute_reply":"2024-07-23T14:12:03.357068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile -a submission/prompts.py \n\n# Put line at top\n\nimport string\nimport unicodedata\n\n\n# None of the Public Keywords have accent marks, so we should convert everything to ASCII\ndef strip_accents(text):\n    try:\n        text = unicode(text, 'utf-8')\n    except NameError: # unicode is a default on python 3 \n        pass\n\n    text = unicodedata.normalize('NFD', text)\\\n           .encode('ascii', 'ignore')\\\n           .decode(\"utf-8\")\n\n    return str(text)\n\n# From Kaggle environment\ndef normalize(s):\n    t = str.maketrans(\"\", \"\", string.punctuation)\n    return strip_accents(s.lower().replace(\"the\", \"\").replace(\" \", \"\").translate(t))\n\n# This class wraps prompt Q&A called by the main agent\nclass Prompter:\n    def __init__(self, model, tokenizer):\n        self.model = model\n        self.tokenizer = tokenizer\n\n    # Turn a stack of messages into an answer\n    def generate_from_messages(self, messages, temp=1.4, max_tokens=256):    \n        input_ids = self.tokenizer.apply_chat_template(\n            messages,\n            add_generation_prompt=True,\n            return_tensors=\"pt\"\n        ).to(self.model.device)\n        \n        terminators = [\n            self.tokenizer.eos_token_id,\n            self.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n        ]\n        \n        outputs = self.model.generate(\n            input_ids,\n            max_new_tokens=256,\n            eos_token_id=terminators,\n            do_sample=True,\n            temperature=temp,\n            top_p=0.9,\n        )\n        response = outputs[0][input_ids.shape[-1]:]\n        return self.tokenizer.decode(response, skip_special_tokens=True)\n\n    # Base wrapper for all system prompts\n    def sys_wrapper(self, sys_prompt):\n        messages = []\n        sys_message = {\"role\": \"system\"}\n        sys_message[\"content\"] = sys_prompt\n        messages.append(sys_message)\n        return messages\n\n    # Combine prompts and run messages\n    def run_prompts(self, messages, prompt, temp=1.4, DEBUG=False):        \n        usr_message = {\"role\": \"user\", \"content\": prompt}\n        if DEBUG:\n            print(prompt + '\\n') \n        messages.append(usr_message)\n        output = self.generate_from_messages(messages, temp)\n        if DEBUG:\n            print(output + '\\n')\n        return output\n        \n    # System prompt for standard list-maker\n    def sys_listmaker(self):\n        return self.sys_wrapper(\"\"\"You are a helpful AI assistant who is skilled in creating diverse lists of objects\n        and asking questions to subdivide these objects into separate categories.\\n\"\"\")\n\n    # System prompt for re-phrasing sentences\n    def sys_rephrase(self):\n        return self.sys_wrapper(\"\"\"You are a helpful AI assistant who is skilled at rephrasing questions. \n        You respect the integrity and meaning of the original sentence and do in-place substitutions only with no hallucinations.\"\"\"   ) \n\n    # System prompt for answering questions\n    def sys_answerer(self):\n        return self.sys_wrapper(\"\"\"You are a helpful AI assistant who is skilled in at answering yes-no-questions. \n        You are highly accurate and demonstrate a strong understanding of question nuances.\"\"\")\n\n    # System prompt for fixing grammar\n    def sys_grammar_editor(self):\n        return self.sys_wrapper(\"\"\"You are a helpful AI assistant who is skilled at editing and understanding grammar, sentence structure, and syntax. \"\"\")\n\n    # Creates diverse lists of 30 things matching input criteria\n    def list_of_thirty(self, pos_plural, prior_pos_plural, location, size, questions=None, answers=None, temp=1.4, DEBUG=False):\n        messages = self.sys_listmaker()\n        \n        ask_prompt = \"Create a list of 30 \" + prior_pos_plural + \" that are \" \n        if len(size) > 0:\n            ask_prompt += size + \" \"\n        ask_prompt += pos_plural \n        if len(location) > 0:\n            ask_prompt += \"typically located in or at \" + location\n        ask_prompt += \". \"\n        #ask_prompt += \"The things must be unique, diverse, \" + pos_plural + \", and as different as possible from each other. \"\n        ask_prompt += \"The \" + pos_plural + \" must be common examples of \" + pos_plural + \" and representative of a range of different possible options. \"\n        # ask_prompt += \"The things must represent examples of as many different categories of \" + pos_plural + \" as possible. \"\n        ask_prompt += \"The answer should be returned as a comma-separated list with no additional verbose output. \"\n        ask_prompt += \"None of the \" + pos_plural + \" may be repeated. \"\n        # ask_prompt += \"Each item in the list should be as different as possible from the prior item. \"\n        ask_prompt += \"No words in the list may be repeated. \"\n        ask_prompt += \"Each of the \" + pos_plural + \" in the list ABSOLUTELY MUST MEET EACH the following criteria:\\n\"\n        for i, q, a in zip(range(0, len(questions)),questions, answers):\n            ask_prompt += \" \" + str(i+1) + \". \" + q + \" \" + a + \".\\n\"\n        ask_prompt += \" Respond with the comma-separated list only. Order the responses according to the most likely or common choices according to the criteria above.\"\n\n        return self.run_prompts(messages, ask_prompt, temp, DEBUG)\n\n    # Creates diverse lists of 30 things matching input criteria, including auto-summary of current knowledge\n    def list_of_thirty_withsummary(self, pos_plural, prior_pos_plural, location, material, size, summary, temp=1.4, DEBUG=False):\n        messages = self.sys_listmaker()\n\n        ask_prompt = \"Create a list of 30 \" + prior_pos_plural + \" that are \" \n        if len(size) > 0:\n            ask_prompt += size + \" \"\n        ask_prompt += pos_plural \n        if material is not None:\n            ask_prompt += \" mostly made of \" + material\n        if len(location) > 0:\n            ask_prompt += \" typically located in or at \" + location\n        ask_prompt += \", \"\n        ask_prompt += f\"matching the following description: {summary}\\n\"\n        #ask_prompt += \"The things must be unique, diverse, \" + pos_plural + \", and as different as possible from each other. \"\n        ask_prompt += \"The \" + pos_plural + \" must be common examples of \" + pos_plural + \" and representative of a range of different possible options. \"\n        # ask_prompt += \"The things must represent examples of as many different categories of \" + pos_plural + \" as possible. \"\n        ask_prompt += \"The answer should be returned as a comma-separated list with no additional verbose output. \"\n        ask_prompt += \"None of the \" + pos_plural + \" may be repeated. \"\n        # ask_prompt += \"Each item in the list should be as different as possible from the prior item. \"\n        ask_prompt += \"No words in the list may be repeated. \"\n        # ask_prompt += \"Each of the \" + pos_plural + \" in the list ABSOLUTELY MUST MEET the following description:\\n\"\n        ask_prompt += \"Respond with the comma-separated list only. Order the responses according to the most likely or common choices according to the criteria above.\"\n\n        return self.run_prompts(messages, ask_prompt, temp, DEBUG)\n\n    # Thirty diverse locations question maker\n    def list_of_thirty_geo(self, type, plural, questions=None, answers=None, temp=1.4, DEBUG=False):\n        messages = self.sys_listmaker()\n        ask_prompt = \"Create a list of 30 geographic \" + plural + \". \"\n        ask_prompt += \"The \" + plural + \" must be unique, diverse, and as different as possible from each other. \"\n        ask_prompt += \"The things must represent examples of as many different categories or geographies of \" + plural + \" as possible. \"\n        ask_prompt += \"The answer should be returned as a comma-separated list with no additional verbose output. \"\n        ask_prompt += \"None of the \" + plural + \" may be repeated. \"\n        ask_prompt += \"Each \" + type + \" in the list should be as different as possible from the prior \" + type + \". \"\n        ask_prompt += \"No words in the list may be repeated. \"\n        ask_prompt += \"Each of the \" + plural + \" in the list should meet the following criteria:\"\n        for i, q, a in zip(range(0, len(questions)),questions, answers):\n            ask_prompt += \" \" + str(i+1) + \". \" + q + \" \" + a + \".\"\n        ask_prompt += \" Respond with the comma-separated list only.\"\n        return self.run_prompts(messages, ask_prompt, temp, DEBUG)\n\n    # Prompt to create two candidate subcategories for a given taxonomic category\n    def split_category(self, prior_pos_plural, plural, negative_categories, temp=1.4, DEBUG=False):\n        messages = self.sys_listmaker()\n        prompt = 'Divide the category \"' + prior_pos_plural + ' that are ' + plural + '\" into two broad, clearly-defined, non-overlapping sub-categories,'\n        prompt += 'ensuring that all ' + prior_pos_plural + ' that are ' + plural + ' fall into one category or the other, but not both. '\n        prompt += 'Respond with the names of the two sub-categories separated by a comma only. Do NOT repeat the original category. Use common phrasing. '\n        prompt += 'Each sub-category must be a noun or noun phrase.'\n        if len(negative_categories) > 0:\n            prompt += \" Do not use any of the following sub-categories: \"\n            for cat, i in zip(negative_categories, range(0, len(negative_categories))):\n                prompt += cat\n                if i < len(negative_categories)-1:\n                    prompt += \", \"\n        return self.run_prompts(messages, prompt, temp, DEBUG)\n\n    # Prompt to create two candidate subcategories for a given taxonomic category, using auto-summary of known information\n    def split_category_withsummary(self, summary, negative_categories, temp=1.4, DEBUG=False):\n        messages = self.sys_listmaker()\n        prompt = 'Divide the category described as \"' + summary + '\" into two broad, clearly-defined, non-overlapping sub-categories,'\n        prompt += 'ensuring that all members of the category fall into one category or the other, but not both. '\n        prompt += 'Respond with the names of the two sub-categories separated by a comma only. Do NOT repeat the original category. Use common phrasing. '\n        prompt += 'Each sub-category must be a noun or noun phrase.'\n        if len(negative_categories) > 0:\n            prompt += \" Do not use any of the following sub-categories: \"\n            for cat, i in zip(negative_categories, range(0, len(negative_categories))):\n                prompt += cat\n                if i < len(negative_categories)-1:\n                    prompt += \", \"\n        return self.run_prompts(messages, prompt, temp, DEBUG)\n\n    # Test whether something belongs to a category or not\n    def question_category(self, category, temp=1.4, DEBUG=False):\n        messages = self.sys_grammar_editor()\n\n        prompt = 'Rephrase the question \"Is it commonly and often described as a '+ category + '?\" '\n        prompt += \" to use correct grammar, including modification of plurality, particle, or gender. Do not change any of the key words or concepts. \"\n        prompt += \"The question should be a simple yes or no question. Respond with the question only without any additional introduction or conclusion.\"\n        return self.run_prompts(messages, prompt, temp, DEBUG)\n\n    # Test whether something is found in a certain location or not\n    def question_location(self, location, temp=1.4, DEBUG=False):\n        messages = self.sys_grammar_editor()\n\n        prompt = 'Rephrase the question \"Are they typically found in or at ' + location + '?\"'\n        prompt += \" to use correct grammar, including modification of plurality, particle, or gender. Do not change any of the key words or concepts. \"\n        prompt += \"The question should be a simple yes or no question. Respond with the question only without any additional introduction or conclusion.\"\n        return self.run_prompts(messages, prompt, temp, DEBUG)\n\n    # Generate noun phrases beginning with a known first word\n    def noun_phrases(self, word, exclude=[], temp=0.6, DEBUG=False):\n        messages = self.sys_grammar_editor()\n        prompt = f\"Create 20 noun phrases describing tangible things that begin with the word '{word}'. Each noun phrase should be exactly two words long, and must begin with the word '{word}' followed by a space without any modification. Respond with the noun phrases in a comma-separated list with no introduction or other additional text.\"\n        if len(exclude) > 0:\n            prompt += \" Do not include any of the following: '\" + \"', '\".join(exclude) + \"'.\"\n        return self.run_prompts(messages, prompt, temp, DEBUG)\n\n    # Is the thing a tangible object?\n    def tangible_object(self, phrase, temp=0.6, DEBUG=False):\n        messages = self.sys_grammar_editor()\n        prompt = f\"Is '{phrase}' typically a tangible thing that can be seen or felt? Respond with a single word yes or no, without any introduction or additional text. Do not add punctuation to the answer.\"\n        return normalize(self.run_prompts(messages, prompt, temp, DEBUG))\n\n    # Test whether the keyword has a particular size\n    def question_size(self, size, temp=1.4, DEBUG=False):\n        messages = self.sys_grammar_editor()\n\n        prompt = 'Rephrase the question \"Are they typically ' + size + '?\"'\n        prompt += \" to use correct grammar, including modification of plurality, particle, or gender. Do not change any of the key words or concepts. \"\n        prompt += \"The question should be a simple yes or no question. Respond with the question only without any additional introduction or conclusion.\"\n        return self.run_prompts(messages, prompt, temp, DEBUG)\n\n    # Fix the grammar of a prompt\n    def fix_grammar(self, prompt, temp=1.4, DEBUG=False):\n        messages = self.sys_grammar_editor()\n        prompt = 'Rephrase the following question to use correct grammar: ' + prompt\n        prompt += ' Do not change any of the key words or concepts. The question should be a simple yes or no question. Respond with the question only without any additional introduction or conclusion.'\n        return self.run_prompts(messages, prompt, temp, DEBUG)\n\n    # Identify the part of speech of a prompt\n    def part_of_speech(self, prompt, temp=0.1, DEBUG=False):\n        messages = self.sys_grammar_editor()\n        prompt = 'What is the English grammar part of speech of the word \"' + prompt + '\"? '\n        prompt += 'Respond with the single word part of speech only. For example, repond with one of the following: noun, adjective, adverb, preposition.'\n        return self.run_prompts(messages, prompt, temp, DEBUG)\n\n    # Find an inverse category descriptor\n    def negative_category(self, category, tested_category, temp=1.4, DEBUG=False):\n        messages = self.sys_listmaker()\n        prompt = 'Create a simple, singular category label for ' + category \n        prompt += ' that are NOT ' + tested_category + ' which includes all other possible ' + category\n        prompt += '. Use common phrasing. Respond with a single label only, with no introductory or concluding text.'\n        return self.run_prompts(messages, prompt, temp, DEBUG)\n        \n    # Thirty diverse things question maker - used in default modality\n    def question_thirty(self, prior_output, questions=None, temp=1.4, DEBUG=False):\n        messages = self.sys_listmaker()\n        \n        chat_template = \"Create a simple yes-or-no question, responding with the question only \"\n        chat_template += \"and no introduction or additional verbose details. \"\n        chat_template += \"The question should broadly categorize and divide the following into two equally-sized lists: \"\n        chat_template += prior_output + \".\\n\\n\"\n        chat_template += \"Do not include questions similar, equivalent, or directly opposite to the following: \"\n        for q in questions:\n            chat_template += q + \", \"\n        chat_template = chat_template[:-2] + \". \"\n        chat_template += \"Ensure that the question is simple, unambiguous, clear, and can be answered either yes or no. \"\n        chat_template += \"Do not create compound questions. \"\n        chat_template += \"The question may explore different aspects or characteristics of the list items including size, appearance, function, location, usage, and other defining characteristics. \"\n        chat_template += \"The question should create a general or broad classification of the two categories and should not be overly specific.\"\n\n        return self.run_prompts(messages, chat_template, temp, DEBUG)\n\n    # Do thirty questions, but using geography\n    def question_thirty_geo(self, type, plural, prior_output, questions=None, temp=1.4, DEBUG=False):\n        messages = self.sys_listmaker()\n\n        chat_template = \"Create a simple positive yes-or-no question, responding with the question only \"\n        chat_template += \"and no introduction or additional verbose details. \"\n        chat_template += \"The question should broadly categorize and divide the following \" + plural + \" into two equally-sized lists: \"\n        chat_template += prior_output + \".\\n\\n\"\n        chat_template += \"Do not include questions similar, equivalent, or directly opposite to the following: \"\n        for q in questions:\n            chat_template += q + \", \"\n        chat_template = chat_template[:-2] + \". \"\n        chat_template += \"Ensure that the question is simple, unambiguous, clear, positively-framed, and can be answered either yes or no. \"\n        chat_template += \"Do not create compound questions. \"\n        chat_template += \"The question may explore different aspects or characteristics of the \" + plural + \" including geographic location by \"\n        chat_template += \"continent, hemisphere, or latitude, population, primary language, membership in international organizations, \"\n        chat_template += \"unique features, or other characteristics. \"\n        chat_template += \"The question should create a general or broad classification of the two categories and should not be overly specific.\"\n\n        return self.run_prompts(messages, chat_template, temp, DEBUG)\n\n    # Rephrase the question with the keyword as subject\n    def rephrase_with_kw(self, question, keyword, temp=1.4, DEBUG=False):\n        messages = self.sys_rephrase()\n        rephrase_prompt = \"Rephrase the following question to use '\" + keyword \n        rephrase_prompt += \"' as the subject of the sentence, adjusting tense, gender, and plurality as needed: \\\"\"\n        rephrase_prompt += question + \"\\\" Respond with the question only and no additional introduction or other text. \"\n        rephrase_prompt += \"Do not change any important words other than the subject of the sentence. The rest of the sentence context should be unaltered.\"\n        return self.run_prompts(messages, rephrase_prompt, temp, DEBUG)\n\n    # The main prompt used by the answerer bot\n    def answer_question(self, question, temp=1.4, DEBUG=False):\n        messages = self.sys_answerer()\n        ask_prompt = f\"In layman's terms, {question} Answer this question in the most general, common sense as possible, ignoring any trivial nuances or exceptions. Please limit response to a single word, either yes or no, with no introduction, conclusion, or other verbose details. Do not add punctuation to the response.\\n\"\n        return normalize(self.run_prompts(messages, ask_prompt, temp, DEBUG))\n\n    # Split the word into singular and plural forms\n    def singular_plural(self, phrase, temp=0.1, DEBUG=False):\n        if phrase is None:\n            return '', ''\n        messages = self.sys_grammar_editor()\n        ask_prompt = \"Give me the singular and plural form of the phrase '\" + phrase \n        ask_prompt += \"' as two entries separated by the word aardvark. List the singular form first, the word aardvark, \"\n        ask_prompt += \"then the plural form. Do not add additional introductory or concluding text.\"\n        output = self.run_prompts(messages, ask_prompt, temp, DEBUG)\n        pieces = output.split(' aardvark ')\n        if len(pieces) == 2:\n            return pieces[0], pieces[1]\n        else:\n            return output, output\n\n    # Is the keyword a proper name? This prompt has a high error rate.\n    def proper_name(self, keyword, temp=0.1, DEBUG=False):\n        messages = self.sys_grammar_editor()\n        prompt = \"Is '\" + keyword + \"' a proper name? Reply yes or no only, with no introduction or extra verbose text. Do not add punctuation to the response.\"\n        return normalize(self.run_prompts(messages, prompt, temp, DEBUG))\n\n    # Find the subject of the sentence\n    def subject(self, question, temp=0.1, DEBUG=False):\n        messages = self.sys_grammar_editor()\n        prompt = \"What noun, noun phrase, or pronoun is the subject of the following question?\\n\"\n        prompt += \"'\" + question + \"' Respond with the subject word only with no introduction or other verbose text. Do not add punctuation to the response.\"\n        return self.run_prompts(messages, prompt, temp, DEBUG)\n\n    # Is the keyword plural?\n    def plural(self, keyword, temp=0.1, DEBUG=False):\n        messages = self.sys_grammar_editor()\n        prompt = \"Is '\" + keyword + \"' in grammatically plural form? Reply yes or no only, with no intoduction or other verbose text. Do not add punctuation to the response.\"\n        return normalize(self.run_prompts(messages, prompt, temp, DEBUG))\n\n    # Create candidate locations where objects of the known category may be found\n    def locations_list(self, second_last_cat, last_cat, temp=1.4, DEBUG=False):\n        messages = self.sys_listmaker()\n        prompt = \"Provide several broad categories of locations where \" + second_last_cat \n        prompt += \" that are \" + last_cat + \" are most often located. Respond with the category names in comma-separated format only.\"\n        output = self.run_prompts(messages, prompt, temp, DEBUG)\n        return output\n\n    # Divide a geographic continent into sub-regions\n    def continental_regions_list(self, continent, temp=1.4, DEBUG=False):\n        messages = self.sys_listmaker()\n        prompt = \"What are a few commonly-used subdivisions to describe country groups within \" + continent \n        prompt += \"? Respond with the subdivisions in comma-separated form with no introduction or additional verbose text.\"\n        output = self.run_prompts(messages, prompt, temp, DEBUG)\n        return output\n\n    # Further divide into sub-sub-regions\n    def continental_region_subs_list(self, continent, region, temp=1.4, DEBUG=False):\n        messages = self.sys_listmaker()\n        prompt = \"What are a few commonly-used subdivisions to describe country groups within the \" + region + \" subregion of \" + continent \n        prompt += \"? Respond with the largest four or five subdivisions in comma-separated form with no introduction or additional verbose text.\"\n        output = self.run_prompts(messages, prompt, temp, DEBUG)\n        return output\n\n    # Divide large countries into smaller regions\n    def country_subregions_list(self, country, temp=1.4, DEBUG=False):\n        messages = self.sys_listmaker()\n        prompt = \"What are a few commonly-used subdivisions to describe groups of states, provinces, or other areas within \" + country \n        prompt += \"? Respond with the largest four or five subdivisions in comma-separated form with no introduction or additional verbose text.\"\n        output = self.run_prompts(messages, prompt, temp, DEBUG)\n        return output\n\n    # Is the keyword a country?\n    def is_a_country(self, to_test, temp=0.6, DEBUG=False):\n        messages = self.sys_answerer()\n        prompt = \"Is \" + to_test + \" a single, sovereign country? Respond with the single word yes or no only, with no added text, verbosity, or punctuation.\"\n        return self.run_prompts(messages, prompt, temp, DEBUG)\n\n    # Enumerate a list of candidate countries within a subregion\n    def country_list(self, continent, region, temp=1.4, DEBUG=False):\n        messages = self.sys_listmaker()\n        if region is not None:\n            prompt = \"Enumerate all of the countries in the \" + region + \" subregion of \" + continent \n        else:\n            prompt = \"Enumerate all of the countries in \" + continent \n        prompt += \", ordered from largest to smallest. Respond with the country names in comma-separated form with no introduction or additional verbose text.\"\n        output = self.run_prompts(messages, prompt, temp, DEBUG)\n        return output\n\n    # More general form of country candidate enumeration\n    def country_list(self, continent, region, subregion, temp=1.4, DEBUG=False):\n        messages = self.sys_listmaker()\n        if region is not None and subregion is not None:\n            prompt = \"Enumerate all of the countries in the \" +subregion+ \" subregion of the \" + region + \" subregion of \" + continent \n        elif region is not None:\n            prompt = \"Enumerate all of the countries in the \" + region + \" subregion of \" + continent \n        else:\n            prompt = \"Enumerate all of the countries in \" + continent \n        prompt += \". Respond with the country names in comma-separated form with no introduction or additional verbose text.\"\n        output = self.run_prompts(messages, prompt, temp, DEBUG)\n        return output\n\n    # Reframe the question-answer pair into a statement of fact. Used for auto-summarization of knowledge.\n    def reframe_as_statement(self, question, answer, temp=1.4, DEBUG=False):\n        messages = self.sys_rephrase()\n        prompt = \"The answer to: \" + question + \" is \" + answer + \". Restate this question and answer as a single statement, accurately reflecting the substance of both the question and the answer. \"\n        prompt += \"Respond with the statement only, with no introduction or other text added.\"\n        output = self.run_prompts(messages, prompt, temp, DEBUG)\n        return output\n\n    # Key function used in auto-summarization of known information\n    def update_summary(self, old_summary, new_statement, temp=1.4, DEBUG=False):\n        messages = self.sys_rephrase()\n        prompt = \"A category is described by the following category summary: \" + old_summary\n        prompt += \" Update this detailed summary to reflect the following new information, consolidating redundant information where needed: \" + new_statement\n        prompt += \" If the new information conflicts with the summary, assume the new information is correct. Do not remove any significant details such as abjectives or exclusions. Respond with the revised, detailed summary text only. Do not add any introduction or additional verbosity.\"\n        output = self.run_prompts(messages, prompt, temp, DEBUG)\n        return output\n\n    # Is this an alphabetical order question?\n    def alpha_check(self, question, temp=0.6, DEBUG=False):\n        messages = self.sys_grammar_editor()\n        prompt = 'Does the question \"' + question + '\" ask whether the keyword comes after another word in alphabetical order, sorting order, and/or lexicographical order? Answer yes or no only with no introduction or additional text. Do not add punctuation to the response.'\n        return normalize(self.run_prompts(messages, prompt, temp, DEBUG))\n\n    # Find comparision word in the alphabetical order question\n    def alpha_extract_word(self, question, temp=0.6, DEBUG=False):\n        messages = self.sys_grammar_editor()\n        prompt = 'What word or letter does the question \"'+question+'\" want me to compare the keyword to? Respond with the noun phrase, word, or letter only. Do not add punctuation to the response.'\n        return self.run_prompts(messages, prompt, temp, DEBUG)\n\n    # What type of ordering are we looking for?\n    def alpha_earlier_later(self, question, test_word, temp=0.6, DEBUG=False):\n        messages = self.sys_grammar_editor()\n        prompt = 'Does the question \"'+question+'\" want me to test whether the keyword is earlier or later compared to \"'+test_word+'\" in lexicographical order? Respond with the word earlier or later only. Do not add punctuation to the response.'\n        return self.run_prompts(messages, prompt, temp, DEBUG)\n\n    # Does the question ask about containing letters?\n    def alpha_container_check(self, question, temp=0.6, DEBUG=False):\n        messages = self.sys_grammar_editor()\n        prompt = 'Does the question \"' + question + ' explicitly list a particular letter or list of letters? Answer yes or no only, with no additional text. Do not add punctuation to the response.'\n        return self.run_prompts(messages, prompt, temp, DEBUG)\n\n    # Extract the test letters from the question\n    def alpha_extract_letters(self, question, temp=0.6, DEBUG=False):\n        messages = self.sys_grammar_editor()\n        prompt = 'What letters does the question \"' + question + '\" want me to test? Respond with the individual letter or letters only in a comma-separated list, with no additional text.'\n        return self.run_prompts(messages, prompt, temp, DEBUG)\n\n    # Does the question ask about the start letter?\n    def alpha_begins_contains(self, question, temp=0.6, DEBUG=False):\n        messages = self.sys_grammar_editor()\n        prompt = 'Does the question \"'+question+'\" want me to test whether the keyword begins with or contains particular letters? Respond with either the single word \"begins\" or \"contains\" only, and do not add any additional text or introduction. Do not add punctuation to the answer.'\n        return self.run_prompts(messages, prompt, temp, DEBUG)\n\n    # Is the question asking me to compare the keyword against an explicit list?\n    def alpha_explicit_list(self, question, temp=0.6, DEBUG=False):\n        messages = self.sys_grammar_editor()\n        prompt = 'Does the question \"'+question+'\" include an explicit list of words or phrases to match an unknown keyword to? Respond with yes or no only. Do not add punctuation to the answer.'\n        return normalize(self.run_prompts(messages, prompt, temp, DEBUG))\n\n    # Extract the explicit list from the question\n    def alpha_extract_list(self, question, temp=0.6, DEBUG=False):\n        messages = self.sys_grammar_editor()\n        prompt = 'What are the entries in the explicit list provided by the question \"'+question+'\" Respond with the list entries in comma-separated format only with no additional text.'\n        return self.run_prompts(messages, prompt, temp, DEBUG)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-25T23:13:35.743128Z","iopub.execute_input":"2024-07-25T23:13:35.743650Z","iopub.status.idle":"2024-07-25T23:13:35.837240Z","shell.execute_reply.started":"2024-07-25T23:13:35.743612Z","shell.execute_reply":"2024-07-25T23:13:35.835737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile -a submission/tagmanager.py \n\n\n# This class stores state information to disk\n# I built this assuming that my agent would be re-initialized at each step\n# However, the objects persist from step to step, so it's easier just to store state information in the objects themselves\n# A simple dictionary would have sufficed.\n\n\nfrom prompts import Prompter\nimport json\nimport os\n\nclass TagManager():\n    def __init__(self, prompter):\n        self.prompter = prompter\n        self.tags = {}\n        self.read_tags()\n\n    # Write tags to file\n    def write_tags(self):\n        with open('tags.json', 'w', encoding='utf-8') as f:\n            json.dump(self.tags, f, ensure_ascii=False, indent=4)\n\n    # Read tags from file\n    def read_tags(self):\n        if os.path.exists('tags.json'):\n            with open('tags.json', 'r') as f:\n                self.tags = json.load(f)\n        else:\n            self.tags = {}\n\n    # Make a new tag, storing both singular and plural forms where appropriate\n    def make_tag(self, label, singular, plural=None):\n        if plural is None:\n            _, p = self.prompter.singular_plural(singular, 0.1, False)\n            s = singular\n            if s == p:\n                s = singular\n                p = singular\n            plural = p\n            singular = s\n        self.tags[label] = (singular, plural)\n        self.write_tags()\n        print(\"Writing tags:\\n\\n\")\n        print(json.dumps(self.tags) + \"\\n\")\n        return (singular, plural)\n\n    # Delete a tag\n    def delete_tag(self, label):\n        if label in self.tags.keys():\n            del self.tags[label]\n            self.write_tags()\n\n    def get_category(self):\n        if \"category\" in self.tags.keys():\n            return self.tags[\"category\"]\n        else:\n            return \"unknown keyword\", \"unknown keywords\"\n\n    def set_category(self, singular, plural=None):\n        s_prior, p_prior = self.get_prior_category()\n        self.make_tag(\"prior category\", s_prior, p_prior)\n        self.make_tag(\"category\", singular, plural)\n\n    def get_prior_category(self):\n        if \"prior category\" in self.tags.keys():\n            return self.tags[\"prior category\"]\n        else:\n            return \"unknown keyword\", \"unknown keywords\"  \n\n    def set_prior_category(self, singular, plural=None):\n        self.make_tag(\"prior category\", singular, plural)\n\n    def get_tested_category(self):\n        if \"tested category\" in self.tags.keys():\n            return self.tags[\"tested category\"]\n        else:\n            return self.get_category()\n\n    def set_tested_category(self, singular, plural=None):\n        self.make_tag(\"tested category\", singular, plural)\n\n    def get_all_tested_categories(self):\n        if \"all tested categories\" in self.tags.keys():\n            return self.tags[\"all tested categories\"]\n        else:\n            return [], []\n\n    def set_all_tested_categories(self, singulars, plurals=[]):\n        if len(singulars) != len(plurals):\n            for i in range(len(singulars)-len(plurals), len(singulars)):\n                plurals.append(self.prompter.singular_plural(singulars[i], 0.1, False)[1])\n        self.make_tag(\"all tested categories\", singulars, plurals)\n        \n\n    def get_alternate_category(self):\n        if \"alternate category\" in self.tags.keys():\n            return self.tags[\"alternate category\"]\n        else:\n            return None, None\n    \n    def set_alternate_category(self, singular, plural=None):\n        self.make_tag(\"alternate category\", singular, plural)\n\n    def set_last_positive_category(self, singular, plural=None):\n        s, p = self.make_tag(\"last positive category\", singular, plural)\n        pos_s, pos_p = self.get_positive_categories()\n        if s not in pos_s:\n            pos_s.append(s)\n            pos_p.append(p)\n            self.set_positive_categories(pos_s, pos_p)\n\n    def get_last_positive_category(self):\n        if \"last positive category\" in self.tags.keys():\n            return self.tags[\"last positive category\"]\n        else:\n            return None, None\n\n\n\n    def get_negative_categories(self):\n        if \"negative categories\" in self.tags.keys():\n            return self.tags[\"negative categories\"]\n        else:\n            return [], []\n\n    def set_negative_categories(self, singulars, plurals=[]):\n        if len(singulars) != len(plurals):\n            for i in range(len(singulars)-len(plurals), len(singulars)):\n                plurals.append(self.prompter.singular_plural(singulars[i], 0.1, False)[1])\n        self.make_tag(\"negative categories\", singulars, plurals)\n\n    def get_positive_categories(self):\n        if \"positive categories\" in self.tags.keys():\n            return self.tags[\"positive categories\"]\n        else:\n            return [\"tangible object\"], [\"tangible objects\"]\n\n    def set_positive_categories(self, singulars, plurals=[]):\n        if len(singulars) != len(plurals):\n            for i in range(len(singulars)-len(plurals), len(singulars)):\n                plurals.append(self.prompter.singular_plural(singulars[i], 0.1, False)[1])\n        self.make_tag(\"positive categories\", singulars, plurals)\n\n    def get_modality(self):\n        if \"modality\" not in self.tags.keys():\n            self.make_tag(\"modality\", \"begin\", \"begin\")\n        return self.tags[\"modality\"]\n\n    def set_modality(self, new_modality):\n        # print(f\"\\nSetting modality {new_modality}\\n\")\n        self.make_tag(\"modality\", new_modality, new_modality)\n\n    def get_locations_list(self):\n        if \"locations_list\" in self.tags.keys():\n            return self.tags[\"locations_list\"]\n        else:\n            return [], []\n\n    def set_locations_list(self, locations_list):\n        self.make_tag(\"locations_list\", locations_list, locations_list)\n\n    def get_continental_regions(self):\n        if \"continental regions\" in self.tags.keys():\n            return self.tags[\"continental regions\"]\n        else:\n            return [], []\n\n    def set_continental_regions(self, continental_regions_list):\n        self.make_tag(\"continental regions\", continental_regions_list, continental_regions_list)\n\n    def get_country_subregions(self):\n        if \"country subregions\" in self.tags.keys():\n            return self.tags[\"country subregions\"]\n        else:\n            return [], []\n\n    def set_country_subregions(self, country_subregions_list):\n        self.make_tag(\"country subregions\", country_subregions_list, country_subregions_list)\n\n    def get_country_list(self):\n        if \"country list\" in self.tags.keys():\n            return self.tags[\"country list\"]\n        else:\n            return [], []\n\n    def set_country_list(self, country_list):\n        self.make_tag(\"country list\", country_list, country_list)\n\n    def set_continental_region(self, continental_region):\n        self.make_tag(\"continental region\", continental_region, continental_region)\n\n    def get_continental_region(self):\n        if \"continental region\" in self.tags.keys():\n            return self.tags[\"continental region\"]\n        else:\n            return None, None\n\n\n\n    def get_iter(self):\n        if \"iter\" not in self.tags.keys():\n            self.make_tag(\"iter\",0, 0)\n        return self.tags[\"iter\"]\n\n    def set_iter(self, new_iter):\n        self.make_tag(\"iter\", new_iter, new_iter)\n\n    def set_location(self, location):\n        self.make_tag(\"location\", location, location)\n\n    def get_location(self):\n        if \"location\" in self.tags.keys():\n            return self.tags[\"location\"]\n        else:\n            return None, None\n\n    def set_material(self, material):\n        self.make_tag(\"material\", material, material)\n\n    def get_material(self):\n        if \"material\" in self.tags.keys():\n            return self.tags[\"material\"]\n        else:\n            return None, None\n\n    def set_size(self, size):\n        self.make_tag(\"size\", size, size)\n\n    def get_size(self):\n        if \"size\" in self.tags.keys():\n            return self.tags[\"size\"]\n        else:\n            return None, None\n\n    def set_landmark_type(self, landmark_type):\n        self.make_tag(\"landmark type\", landmark_type, landmark_type)\n\n    def get_landmark_type(self):\n        if \"landmark type\" in self.tags.keys():\n            return self.tags[\"landmark type\"]\n        else:\n            return None, None\n\n    def get_statements_list(self):\n        if \"statements list\" in self.tags.keys():\n            return self.tags[\"statements list\"]\n        else:\n            return [], []\n\n    def set_statements_list(self, statements_list):\n        self.make_tag(\"statements list\", statements_list, statements_list)\n\n    def get_summary(self):\n        if \"summary\" in self.tags.keys():\n            return self.tags[\"summary\"]\n        else:\n            return \"A thing.\", \"A thing.\"\n\n    def set_summary(self, summary):\n        self.make_tag(\"summary\", summary, summary)\n\n    def get_proper_name(self):\n        if \"proper name\" in self.tags.keys():\n            return self.tags[\"proper name\"]\n        else:\n            return None, None\n\n    def set_proper_name(self, yesno):\n        self.make_tag(\"proper name\", yesno, yesno)\n\n    def get_article(self):\n        if \"article\" in self.tags.keys():\n            return self.tags[\"article\"]\n        else:\n            return '', ''\n\n    def set_article(self, article):\n        self.make_tag(\"article\", article, article)\n\n    def get_plural(self):\n        if \"plural\" in self.tags.keys():\n            return self.tags[\"plural\"]\n        else:\n            return \"no\", \"no\"\n\n    def set_plural(self, yesno):\n        self.make_tag(\"plural\", yesno, yesno)\n\n    def get_type(self):\n        if \"type\" in self.tags.keys():\n            return self.tags[\"type\"]\n        else:\n            return None, None\n\n    def set_type(self, type, plural=None):\n        self.make_tag(\"type\", type, plural)\n\n    def set_continent(self, continent, continent_adj):\n        self.make_tag(\"continent\", continent, continent_adj)\n\n    def get_continent(self):\n        if \"continent\" in self.tags.keys():\n            return self.tags[\"continent\"]\n        else:\n            return None, None\n\n    def set_country(self, country):\n        self.make_tag(\"country\", country, country)\n\n    def get_country(self):\n        if \"country\" in self.tags.keys():\n            return self.tags[\"country\"]\n        else:\n            return None, None\n\n    def set_country_subregion(self, country_subregion):\n        self.make_tag(\"country subregion\", country_subregion, country_subregion)\n\n    def get_country_subregion(self):\n        if \"country subregion\" in self.tags.keys():\n            return self.tags[\"country subregion\"]\n        else:\n            return None, None\n\n\n    def set_continental_region_sub(self, continental_region_sub):\n        self.make_tag(\"continental region sub\", continental_region_sub, continental_region_sub)\n\n    def get_continental_region_sub(self):\n        if \"continental region sub\" in self.tags.keys():\n            return self.tags[\"continental region sub\"]\n        else:\n            return None, None\n\n    def set_continental_region_subs(self, continental_region_subs):\n        self.make_tag(\"continental region subs\", continental_region_subs, continental_region_subs)\n\n    def get_continental_region_subs(self):\n        if \"continental region subs\" in self.tags.keys():\n            return self.tags[\"continental region subs\"]\n        else:\n            return [],[]\n\n    ","metadata":{"execution":{"iopub.status.busy":"2024-07-25T23:13:48.065259Z","iopub.execute_input":"2024-07-25T23:13:48.065702Z","iopub.status.idle":"2024-07-25T23:13:48.141444Z","shell.execute_reply.started":"2024-07-25T23:13:48.065667Z","shell.execute_reply":"2024-07-25T23:13:48.140235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile -a submission/main.py\n\n# Set up the agent\nimport os\nKAGGLE_AGENT_PATH = \"/kaggle_simulations/agent/\"\nif os.path.exists(KAGGLE_AGENT_PATH):\n    model_id = os.path.join(KAGGLE_AGENT_PATH, \"llama-3-1\")\nelse:\n#     model_id = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"\n    model_id = \"/kaggle/tmp/llama-3-1\"\n    \n# Load keyword files\nif os.path.exists(KAGGLE_AGENT_PATH):\n    keywords_txt = os.path.join(KAGGLE_AGENT_PATH, \"keywords.txt\")\n#     kw_cat_txt = os.path.join(KAGGLE_AGENT_PATH, \"kw_cats_for_test.csv\")\n    freq_csv = os.path.join(KAGGLE_AGENT_PATH, \"my_freq.csv\")\nelse:\n    keywords_txt = \"/kaggle/input/keyword-list/keywords.txt\"\n#     kw_cat_txt = \"/kaggle/input/kw-kats/kw_cats_for_test.csv\"\n    freq_csv = \"/kaggle/input/frequencies/my_freq.csv\"\n\n# Debug flags\nDUMB_GUESSER = False\nFIXED_KEYWORD = None\n\n#----------- Copy from here down\n\nPRECAT_ON = False # Disable my offline analysis - it underperformed versus my online-only solution\n\nTEMPERATURE = 1.4 # Default temperature. Overridden in most cases\nDEBUG = True\n\nimport transformers\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom transformers import pipeline\nimport torch\nimport sys\nimport shutil\nimport unicodedata\nimport pandas as pd\nimport math\nimport random\nimport re\nimport datetime\nimport string\n\n\n\n# I thought about having the agent automatically switch over keyword lists on the submission deadline\n# However, I didn't want to risk introducing any last-minute bugs into the code, so didn't do this.\n\n# KEYWORD_BIAS = 'on' # Keyword bias causes the LLM to prefer guesses in a pre-defined keyword list\n\n# day = datetime.datetime.today().day\n# month = datetime.datetime.today().month\n\n# Time the keyword exclusion date to kick in in 8/13\n# if month > 8 or (month >= 8 and day > 13):\n\nKEYWORD_BIAS = 'exclude' # Exclude all known public keywords from guessing\nAGENT_ALPHA = True # Turn on alpha binary search behavior\n\ntransformers.logging.set_verbosity_error()\n\n# Replace non-ASCII characters with ASCII equivalents\ndef strip_accents(text):\n    try:\n        text = unicode(text, 'utf-8')\n    except NameError: # unicode is a default on python 3 \n        pass\n\n    text = unicodedata.normalize('NFD', text)\\\n           .encode('ascii', 'ignore')\\\n           .decode(\"utf-8\")\n\n    return str(text)\n\n# From Kaggle environments code\ndef normalize(s):\n    t = str.maketrans(\"\", \"\", string.punctuation)\n    return strip_accents(s.lower().replace(\"the\", \"\").replace(\" \", \"\").translate(t))\n\n# From Kaggle environments code\ndef compare_words(a, b):\n    a = normalize(a)\n    b = normalize(b)\n    if a == b:\n        return True\n    # don't check for plurals if string is too short\n    if len(a) < 3 or len(b) < 3:\n        return False\n    # accept common plurals\n    if a[-1] == \"s\" and a[:-1] == b:\n        return True\n    if b[-1] == \"s\" and a == b[:-1]:\n        return True\n    if a[-2:] == \"es\" and a[:-2] == b:\n        return True\n    if b[-2:] == \"es\" and a == b[:-2]:\n        return True\n    return False\n\n# Is the keyword in a particular list (using Kaggle environment comparison function)?\ndef already_in(new_word, wordlist):\n    for word in wordlist:\n        if compare_words(new_word, word):\n            return True\n    return False\n\nfrom prompts import Prompter\nfrom tagmanager import TagManager\n\n# Clean up tags after old run - should not exist, assuming environment fully reset between games\nif os.path.exists(\"tags.json\"):\n    os.remove(\"tags.json\")   \n\ntorch.backends.cuda.enable_mem_efficient_sdp(False)\ntorch.backends.cuda.enable_flash_sdp(False)\n\n# Load the model (Llama 3.1 7B 8-bit quantized)\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForCausalLM.from_pretrained(model_id, load_in_8bit=True, torch_dtype=torch.bfloat16, device_map=\"auto\")\nmodel.generation_config.pad_token_id = tokenizer.pad_token_id\nid_eot = tokenizer.convert_tokens_to_ids([\"<|eot_id|>\"])[0]\n\n# Candidate \"sizes\" that they keyword may be\nsize_list = [\"small\", \"large\"]\n\ndef generate_from_messages(messages, temp=TEMPERATURE, max_tokens=256):\n    \n    input_ids = tokenizer.apply_chat_template(\n        messages,\n        add_generation_prompt=True,\n        return_tensors=\"pt\"\n    ).to(model.device)\n    \n    terminators = [\n        tokenizer.eos_token_id,\n        tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n    ]\n    \n    outputs = model.generate(\n        input_ids,\n        max_new_tokens=256,\n        eos_token_id=terminators,\n        do_sample=True,\n        temperature=temp,\n        top_p=0.9,\n    )\n    response = outputs[0][input_ids.shape[-1]:]\n    return tokenizer.decode(response, skip_special_tokens=True)\n\ndef generate_answer(template, max_tokens=15):\n    inp_ids = tokenizer(template, return_tensors=\"pt\").to(\"cuda\")\n    out_ids = model.generate(**inp_ids,max_new_tokens=max_tokens).squeeze()\n    start_gen = inp_ids.input_ids.shape[1]\n    out_ids = out_ids[start_gen:]\n    if id_eot in out_ids:\n        stop = out_ids.tolist().index(id_eot)\n        out = tokenizer.decode(out_ids[:stop])\n    else:\n        out = tokenizer.decode(out_ids)\n    return out\n  \n\nclass Robot:\n    def __init__(self, fixed_keyword = None):\n        self.p = Prompter(model, tokenizer)\n\n        # Some keyword corrections\n        self.keyword_supply = ['mount mckinley', 'mt mckinley', 'mt st helens', \n                           'mt everest', 'mount everest', 'mount cook', 'mt cook', 'amazonas',\n                          'ganges river', 'changjiang', 'huang he', \"kiev\", \"kyiv\", \"kyiv ukraine\",\n                          'saigon', 'usa', 'united states', 'uk', 'great britain', 'eswatini',\n                          'republic of korea', 'democratic peoples republic of korea', 'dprk', 'holland',\n                          'burma', 'congo kinshasa', 'air conditioning', 'cardboard boxes', 'fan',\n                          'coffee machine', 'coffee machines', 'comic', 'comics', 'diving platform',\n                          'Dumbbell Weights', 'facial mask', 'pier', 'fungus', 'fuses', 'hair tie', 'hdmi',\n                          'irrigation', 'khakis', 'laundry hamper', 'mice', 'ppe', 'pa', 'pop', 'soda-pop',\n                          'speaker system', 'tea leaves', 'tv', 'touchscreen displays', 'trash bin', 'willow',\n                          'aerator', 'decanter', ]\n\n        # Some corrections to the public keyword set\n        self.corrections = {'korea': 'south korea', 'mount saint elias': 'mount saint lias', 'mount denali': 'denali',\n                           'mt st. helens': 'mount saint helens', 'mount st. helens': 'mount saint helens', 'amazon river': 'amazon', 'dnieper river': 'dnieper',\n                           'rhine river': 'rhine', 'nile river': 'nile', 'mount sumantri': 'sumantri', 'mount puncak jaya':\n                           'puncak jaya', 'mount haleakala': 'haleakala', 'mount kangchenjunga': 'kangchenjunga',\n                           'mount nanga parbat': 'nanga parbat', 'mount dhaulagiri': 'dhaulagiri', 'mount annapurna': 'annapurna',\n                           'mount manaslu': 'manaslu', 'mount cho oyu': 'cho oyu', 'mount makalu': 'makalu', \n                           'mount lhotse': 'lhotse', 'mount zugspitze': 'zugspitze', 'mount chimborazo': 'chimborazo',\n                           'mount cotopaxi': 'cotopaxi', 'mount fitz roy': 'fitz roy', 'mount aconcagua': 'aconcagua',\n                           'mount iztaccihuatl': 'iztaccihuatl', 'nail clippers': 'nail clipper'}\n\n        self.reset(fixed_keyword)\n        \n\n    def reset(self, fixed_keyword):\n\n        # If we are re-setting, eliminate all old tags\n        if os.path.exists(\"tags.json\"):\n            print(\"Deleting existing tags\\n\")\n            os.remove(\"tags.json\")  \n        \n        self.tagman = TagManager(self.p)\n        self.fixed_keyword = fixed_keyword\n        self.alpha_on = False\n        self.testwords = []\n        self.tested_phrases = []\n\n        # Load the public keyword list\n        if os.path.exists(keywords_txt):\n            print(\"Found keyword file\\n\\n\")\n            file1 = open(keywords_txt, 'r')\n            Lines = file1.readlines()\n\n            # Add the keyword to our keyword supply\n            count = 0\n            for line in Lines:\n                if count > 0:\n                    parts = line.split(',')\n                    if len(parts) == 3:\n                        category = parts[2].strip().lower()\n                        kw = parts[1].strip().lower()\n                        self.keyword_supply.append(kw.lower())\n                count += 1\n            print(f\"Loaded {str(len(self.keyword_supply))} keywords.\\n\\n\")\n        else:\n            print(\"No keyword file found!\\n\\n\")\n\n        self.freq = {}\n        self.first_candidates = []\n        self.second_candidates = []\n        self.candidate_phrases = []\n        self.first_word = None\n        self.second_word = None\n        \n        # Load the unigram frequency list for alpha searching\n        if os.path.exists(freq_csv):\n            print(\"Found frequency file\\n\\n\")\n            file1 = open(freq_csv, 'r')\n            Lines = file1.readlines()\n\n            # Add the keyword to our frequency data and candidates list\n            count = 0\n            for line in Lines:\n                if count > 0:\n                    parts = line.split(',')\n                    self.freq[parts[0].lower().strip()] = int(parts[1].lower().strip())\n                    self.first_candidates.append(parts[0].lower().strip())\n                    self.second_candidates.append(parts[0].lower().strip())\n                count += 1\n            print(f\"Loaded {str(len(self.freq))} frequency entries.\\n\\n\")\n            self.first_candidates.sort()\n            self.second_candidates.sort()\n        else:\n            print(\"No frequency file found!\\n\\n\")\n\n#         self.kw_cat = pd.read_csv(kw_cat_txt)\n#         print(self.kw_cat.sum())\n\n    # Filter out obviously incorrect phrase choices\n    def valid_phrase(self, phrase, obs):\n        c = strip_accents(phrase.lower().strip())\n        print(c)\n        if self.first_word is not None:\n            if len(c) > len(self.first_word) and c[len(self.first_word)] != ' ' and ' ' not in c:\n                c = self.first_word + ' ' + c[len(self.first_word):]\n            elif len(c) > len(self.first_word) and c[len(self.first_word)] != ' ':\n                print(\"non contiguous\")\n                return None\n        if already_in(c, self.keyword_supply):\n            print(\"in kw supply\")\n            return None\n        if already_in(c, obs.guesses):\n            print(\"in guesses\")\n            return None\n        for a, testword in zip(obs.answers[1:], self.testwords):\n            if a == 'yes' and c >= testword:\n                print(\"already excluded\")\n                return None\n            if a == 'no' and c < testword:\n                print(\"already excluded\")\n                return None\n        to = self.p.tangible_object(c)\n        if to.strip().lower() == 'no':\n            print(\"not tangible\")\n            return None\n        return c\n    \n    def on(self, mode, obs):\n        assert mode in [\"asking\", \"guessing\", \"answering\"], \"mode can only take one of these values: asking, answering, guessing\"\n        \n        if mode == \"asking\":\n            #launch the asker role\n            output = self.asker(obs)\n        if mode == \"answering\":\n            #launch the answerer role\n            output = self.answerer(obs)\n            if \"yes\" in output.lower():\n                output = \"yes\"\n            elif \"no\" in output.lower():\n                output = \"no\"   \n            if (\"yes\" not in output.lower() and \"no\" not in output.lower()):\n                output = \"yes\"\n        if mode == \"guessing\":\n            #launch the guesser role\n            output = self.asker(obs)\n        if DEBUG:\n            print(output)\n        return output\n    \n    \n    def asker(self, obs):\n   \n        if obs.turnType ==\"ask\":\n            if DEBUG:\n                print(\"ASKER:\\n\")\n\n            # Default first question - skip if KEYWORD_BIAS is off\n            if len(obs.questions)<1 and AGENT_ALPHA:\n                output = \"\"\"Is it Agent Alpha?\"\"\"\n                return output\n            elif len(obs.questions)<1:\n                if PRECAT_ON:\n                    self.tagman.set_modality('precat') # Go to offline category mode\n                else:\n                    self.tagman.set_modality('category') # Go to online category mode (used in final submission)\n\n            # Determine preferred modality to use \n            modality, _ = self.tagman.get_modality()\n\n            #-----------------------------------------------------------\n            # BEGIN MODALITY\n            #-----------------------------------------------------------\n            assert (modality != 'begin')\n                \n            # Code for \"THINGS\" ##########################################\n            #------------------------------------------------------\n            # MODALITY DETERMINATION\n            #------------------------------------------------------\n\n            # This code determines if the modality needs to change\n            \n            if modality == 'first_word':\n                if self.first_word is not None:\n                    modality = 'second_word'\n                    self.tagman.set_modality(modality)\n                if len(self.first_candidates) == 0:\n                    if PRECAT_ON:\n                        self.tagman.set_modality('precat')\n                    else:\n                        self.tagman.set_modality('category')\n                    self.tagman.set_modality(modality)\n\n            if modality == 'second_word':\n                if len(self.second_candidates) == 0:\n                    if PRECAT_ON:\n                        self.tagman.set_modality('precat')\n                    else:\n                        self.tagman.set_modality('category')\n                    self.tagman.set_modality(modality)\n            \n            # Determine if modality should change\n            if modality == 'precat':\n                pass\n                    \n            if modality == 'category':\n                if len(obs.answers) > 6:\n                    if len(obs.answers) >= 13 or (obs.answers[-1] == 'no' and obs.answers[-2] == 'no' and obs.answers[-3] == 'no' and obs.answers[-4] == 'no'):\n                        location, _ = self.tagman.get_location()\n                        if location is None:\n                            self.tagman.set_modality(\"location\")\n                            print('\\n\\nSWITCHING TO LOCATION\\n\\n')\n                        else:\n                            self.tagman.set_modality(\"size\")\n\n            if modality == 'location':\n                current_location, _ = self.tagman.get_location()\n                locations_list, _ = self.tagman.get_locations_list()\n                continent, _ = self.tagman.get_continent()\n                iter, _ = self.tagman.get_iter()\n                if continent is not None: # Don't do size or location for places\n                    modality = \"default\"\n                    self.tagman.set_modality(\"default\")\n                    self.tagman.set_iter(0)\n                if (current_location is not None and current_location.lower().strip() not in ['nature', 'indoors', 'outdoors', 'home']) or \\\n                    iter == len(locations_list) or iter > 5:\n                    modality = \"size\"\n                    self.tagman.set_modality(\"size\")\n                    self.tagman.set_iter(0)\n                    \n            if modality == 'size':\n                iter, _ = self.tagman.get_iter()\n                iter = int(iter)\n                size, _ = self.tagman.get_size()\n                if size is not None or iter >= len(size_list):\n                    self.tagman.set_modality(\"default\")\n                    modality = \"default\"\n                    self.tagman.set_iter(0)\n\n            modality, _ = self.tagman.get_modality()\n\n\n            # ---------------------------------------------------------\n            # FIRST WORD MODALITY - find the first word of the keyword\n            # ---------------------------------------------------------\n            if modality == 'first_word':\n                index = len(self.first_candidates) // 2\n                try:\n                    keyword = self.first_candidates[index]\n                except Exception as e:\n                    print(self.first_candidates)\n                    raise e\n                self.testwords.append(keyword)\n                output = f\"Does the keyword (in lowercase) come before \\\"{keyword}\\\" in alphabetical order?\"\n\n            # ---------------------------------------------------------\n            # SECOND WORD MODALITY - find the second word of the keyword\n            # --------------------------------------------------------- \n\n            if modality == 'second_word':\n                if len(self.candidate_phrases) >= 2:\n                    index = len(self.candidate_phrases) // 2 \n                    cpy = [x for x in self.candidate_phrases]\n                    cpy.sort()\n                    keyword = cpy[index]\n                    self.testwords.append(keyword)\n                    output = f\"Does the keyword (in lowercase) come before \\\"{keyword}\\\" in alphabetical order?\"\n                else:\n                    index = len(self.second_candidates) // 2\n                    keyword = self.first_word + ' ' + self.second_candidates[index]\n                    self.testwords.append(keyword)\n                    output = f\"Does the keyword (in lowercase) come before \\\"{keyword}\\\" in alphabetical order?\"\n            \n            # ---------------------------------------------------------\n            # PRECAT MODALITY - use offline computed categories [DISABLED]\n            # ---------------------------------------------------------\n            if modality == 'precat':\n                pass\n\n            try:\n                # ---------------------------------------------------------\n                # CATEGORY MODALITY - automatically compute taxonomic categories\n                # ---------------------------------------------------------\n                if modality == 'category':                   \n    \n                    should_subcategorize = True\n                    \n                    if self.tagman.get_category()[0] == \"unknown keyword\":\n                        if self.tagman.get_type()[0] is not None:\n                            self.tagman.make_tag(\"category\", self.tagman.get_type()[0])\n                            self.tagman.set_last_positive_category(\"place\") \n                        else:\n                            self.tagman.make_tag(\"category\", \"tangible object\")\n                            self.tagman.set_last_positive_category(\"tangible object\")                \n    \n                    # Refine the category\n                    if \"tested category\" in self.tagman.tags.keys():\n                        answer = obs.answers[-1]\n                        t_single, t_plural = self.tagman.get_tested_category()\n                        \n                        if answer.lower().strip() == 'no': # Failure!\n    \n                            # See if there was an alternate which we should now test\n                            if \"alternate category\" in self.tagman.tags.keys():\n                                alt_single, alt_plural = self.tagman.get_alternate_category()\n                                self.tagman.set_category(alt_single, alt_plural)\n                                self.tagman.set_tested_category(alt_single, alt_plural)\n                                self.tagman.delete_tag(\"alternate category\")\n                                should_subcategorize = False # Test this first before sub-categorizing\n                            else:\n                                # If there's no alternate, we tested both and both failed. Skip back to the last positive category.\n                                pos_singular, pos_plural = self.tagman.get_last_positive_category()\n                                self.tagman.set_category(pos_singular, pos_plural)\n                                self.tagman.set_tested_category(pos_singular, pos_plural)\n                                should_subcategorize = True\n                        \n    \n                    singular_to_test, plural_to_test = self.tagman.get_category()\n    \n                    # Get all previously tested categories\n                    all_singular, all_plural = self.tagman.get_all_tested_categories()\n                    \n                    if should_subcategorize:                    \n                        # Create subcategories\n                        _, positive_categories = self.tagman.get_positive_categories()\n                        if len(positive_categories) > 1:\n                            prior_positive_category = positive_categories[-2]\n                        else:\n                            prior_positive_category = 'things'\n    \n                        # Find candidate subcategories\n                        output = self.p.split_category(prior_positive_category, plural_to_test, all_plural, 0.6, DEBUG)\n                        \n                        # Test the first category\n                        parts = output.split(',')\n                        if len(parts) == 1:\n                            parts = output.split(' and ')\n                        self.tagman.make_tag(\"tested category\", parts[0]) # Record the category we are testing\n                        if len(parts) > 1:\n                            self.tagman.make_tag(\"alternate category\", parts[1]) # Record the alternate that we're not testing\n                        singular_to_test = parts[0]                    \n                        singular_to_test, plural_to_test = self.p.singular_plural(singular_to_test, 0.1, DEBUG)\n    \n                    # Record this as a tested category\n                    all_singular.append(singular_to_test)\n                    all_plural.append(plural_to_test)\n                    self.tagman.set_all_tested_categories(all_singular, all_plural)\n    \n                    # Make a question to test category membership\n                    words = singular_to_test.split(' ')\n                    #part_of_speech = self.p.part_of_speech(words[-1])\n                    output = self.p.question_category(singular_to_test, 0.1, DEBUG)              \n        \n                # ---------------------------------------------------------\n                # LOCATION MODALITY - automatically enumerate and test possible locations where the keyword exists\n                # ---------------------------------------------------------\n                elif modality == 'location':  \n                    # Initialize the location search\n                    locations_list, _ = self.tagman.get_locations_list()\n                    iter, _ = self.tagman.get_iter()\n                    iter = int(iter)\n    \n                    # Find last and second to last category\n                    cat_single, cat_plural = self.tagman.get_positive_categories()\n                    last_cat = cat_plural[-1]\n                    if len(cat_plural) > 1:\n                        second_last_cat = cat_plural[-2]\n                    else:\n                        second_last_cat = \"things\"\n    \n                    # Get a list of locations if we don't have one yet\n                    if len(locations_list) == 0:    \n                        # Create a list of locations to search\n                        locations_list = self.p.locations_list(second_last_cat, last_cat, 1.0, DEBUG).split(',')\n                        self.tagman.set_locations_list(locations_list)\n    \n                    # Test if the keyword typically found in this location\n                    location_to_test = locations_list[iter]\n                    output = self.p.question_location(location_to_test, 0.1, DEBUG)  \n    \n                #---------------------------------------------------------\n                # SIZE MODALITY - test possible sizes of the keyword\n                #---------------------------------------------------------\n    \n                elif modality == 'size':\n                    iter, _ = self.tagman.get_iter()\n                    iter = int(iter)\n                    size_to_test = size_list[int(iter)]\n    \n                    output = self.p.question_size(size_to_test, 0.1, DEBUG)\n    \n                #---------------------------------------------------------\n                # DEFAULT MODALITY - enumerate possible keywords and create question to attempt to categorize them\n                #---------------------------------------------------------\n    \n                elif modality == 'default':\n            \n                    # Get known information tags about the keyword\n                    pos_s, pos_p = self.tagman.get_positive_categories()\n                    prior_category_plural = 'things'\n                    category_plural = 'tangible things'\n                    if len(pos_p) >= 2:\n                        category_plural = pos_p[-1]\n                        prior_category_plural = pos_p[-2]\n                    location, _ = self.tagman.get_location()\n                    if location is None:\n                        location = ''\n                    size, _ = self.tagman.get_size()\n                    if size is None:\n                        size = ''\n    \n                    material, _ = self.tagman.get_material() # Only exists for precat modality\n    \n                    # Enumerate possible keywords\n                    summary, _ = self.tagman.get_summary()\n                    output = self.p.list_of_thirty_withsummary(category_plural, prior_category_plural, location, material, size, summary, 0.1, DEBUG)  \n                \n                    if output is None:\n                        print ('\\n\\n\\nERROR!!!!!!!!!!!\\n\\n\\n')\n                        output = \"Physical objects\"\n    \n                    # Now create a question to distinguish these things\n                    output = self.p.question_thirty(output, obs.questions, 1.0, DEBUG)\n            \n            except Exception as e:\n                print(self.tagman.tags)\n                raise e\n                    \n                    \n        elif obs.turnType == \"guess\":\n\n            output = None\n            output_type = 'things'\n            \n            # Create a factual statement with new information gleaned from the question-answer pair\n            if obs.questions[-1] != \"Is it Agent Alpha?\" and not self.alpha_on:\n                statement = self.p.reframe_as_statement(obs.questions[-1], obs.answers[-1], 0.1)\n                statements, _ = self.tagman.get_statements_list()\n                statements.append(statement)\n                self.tagman.set_statements_list(statements)\n\n                # Update auto-summary information with new fact obtained\n                summary, _ = self.tagman.get_summary()\n                new_summary = self.p.update_summary(summary, statement, 0.2, DEBUG)\n                self.tagman.set_summary(new_summary)\n            else:\n                summary = \"A thing.\"\n\n            # Update modal data with new information received\n            modality, _ = self.tagman.get_modality()\n\n            # Get most recent answer\n            answer = obs.answers[-1]\n\n            # Get iterator\n            iter, _ = self.tagman.get_iter()\n\n            # Record begin answer\n            if modality == 'begin':\n                if answer.lower().strip() == 'yes' and AGENT_ALPHA: # Did answerer accept the handshake?\n                    self.alpha_on = True\n                    self.tagman.set_modality('first_word')\n                else:\n                    if PRECAT_ON:\n                        self.tagman.set_modality('precat')\n                    else:\n                        self.tagman.set_modality('category')\n                modality, _ = self.tagman.get_modality()\n\n            elif modality == 'first_word':\n                \n                # Is the keyword earlier or later than the test word in alphabetical order?\n                \n                print(len(self.first_candidates))\n                if len(self.first_candidates) == 4:\n                    print(self.first_candidates)\n                testword = self.testwords[-1]\n                new_candidates = []\n                if answer.lower().strip() == 'yes':\n                    for word in self.first_candidates:\n                        if word < testword:\n                            new_candidates.append(word)\n                        else:\n                            break\n                else:\n                    for word in self.first_candidates:\n                        if word >= testword:\n                            new_candidates.append(word)\n                self.first_candidates = new_candidates\n\n                # If candidates reduced to one, then go on to second word modality\n                if len(self.first_candidates) == 1:\n                    print(f\"Found single candidate word: {self.first_candidates[0]}\\n\")\n                    self.tagman.set_modality('second_word')\n                    self.first_word = self.first_candidates[0]\n                    \n                    # Automatically enumerate noun phrase candidate list\n                    phrase_candidates = self.p.noun_phrases(self.first_word, self.tested_phrases).split(', ')\n                    if len(phrase_candidates) == 1:\n                        phrase_candidates = self.p.noun_phrases(self.first_word, self.tested_phrases).split(',')\n                    print(phrase_candidates)\n\n                    # Check validity of generated candidates\n                    for candidate in [self.first_word] + phrase_candidates:\n                        valid_c = self.valid_phrase(candidate, obs)\n                        if valid_c is not None and valid_c not in self.candidate_phrases:\n                            self.candidate_phrases.append(valid_c)\n                    self.tested_phrases = self.tested_phrases + self.candidate_phrases\n                \n            elif modality == 'second_word':\n                \n                # See what information we gained and reduce our candidate set accordingly\n                \n                testword = self.testwords[-1].split(' ')[1]\n                new_candidates = []\n                new_phrases = []\n                if answer.lower().strip() == 'yes':\n                    for word in self.second_candidates:\n                        if word < testword:\n                            new_candidates.append(word)\n                        else:\n                            break\n                    for phrase in self.candidate_phrases:\n                        if phrase < self.testwords[-1]:\n                            new_phrases.append(phrase)\n                else:\n                    for word in self.second_candidates:\n                        if word >= testword:\n                            new_candidates.append(word)\n                    for phrase in self.candidate_phrases:\n                        if phrase >= self.testwords[-1]:\n                            new_phrases.append(phrase)\n                self.second_candidates = new_candidates\n                self.candidate_phrases = new_phrases  \n                print(self.candidate_phrases)\n\n            # DISABLED in final submission\n            elif modality == 'precat':\n                pass          \n\n            # Record new information gained about taxonomic category\n            elif modality == 'category':\n                if \"tested category\" in self.tagman.tags.keys():\n                    t_single, t_plural = self.tagman.get_tested_category()\n                    if answer.lower().strip() == 'yes':\n                        \n                        # Set the category according to the answer we've found\n                        self.tagman.set_category(t_single, t_plural)\n                        self.tagman.set_last_positive_category(t_single, t_plural)\n                        self.tagman.set_tested_category(t_single, t_plural)\n                        self.tagman.delete_tag(\"alternate category\") # Discard the alternate\n                    else:\n                        # Record this as a negative category\n                        neg_single, neg_plural = self.tagman.get_negative_categories()\n                        neg_single.append(t_single)\n                        neg_plural.append(t_plural)\n                        self.tagman.set_negative_categories(neg_single, neg_plural)\n                        \n            # Record new information gained about the location of the keyword\n            elif modality == 'location':\n                \n                # Update location iter\n                iter, _ = self.tagman.get_iter()\n                locations_list, _ = self.tagman.get_locations_list()\n                iter = int(iter)\n                if obs.answers[-1] == 'yes':\n                    self.tagman.set_location(locations_list[iter])\n                self.tagman.set_iter(iter+1)\n                \n            # Record new information about the size of the keyword\n            elif modality == 'size':\n                iter, _ = self.tagman.get_iter()\n                iter = int(iter)\n                if obs.answers[-1] == 'yes':\n                    self.tagman.set_size(size_list[iter])\n                self.tagman.set_iter(iter+1)\n            \n            if DUMB_GUESSER:\n                return \"null guess\"\n            \n            if DEBUG:\n                print(\"GUESSER:\\n\")     \n\n\n            ###################3\n            # ALPHA CODE\n            ###################3\n\n            # Enumerate possible noun phrases based on a known first word in the keyword\n            if self.first_word is not None and len(self.candidate_phrases) == 0:\n                \n                # Try and generate new candidate phrases\n                phrase_candidates = self.p.noun_phrases(self.first_word, self.tested_phrases).split(', ')\n                if len(phrase_candidates) == 1:\n                    phrase_candidates = self.p.noun_phrases(self.first_word, self.tested_phrases).split(',')\n                print(phrase_candidates)\n\n                # Eliminate invalid candidates from consideration\n                for candidate in [self.first_word] + phrase_candidates:\n                    valid_c = self.valid_phrase(candidate, obs)\n                    if valid_c is not None and valid_c not in self.candidate_phrases:\n                        self.candidate_phrases.append(valid_c)\n                self.tested_phrases = self.tested_phrases + self.candidate_phrases\n                \n            # If we have some candidate noun phrases, just use the first one\n            if len(self.candidate_phrases) > 0:\n                output = self.candidate_phrases[0]\n                if len(self.candidate_phrases) > 1:\n                    self.candidate_phrases = self.candidate_phrases[1:]\n                else:\n                    self.candidate_phrases = []\n                return output\n\n            # If we haven't found the first word of the keyword yet\n            if self.alpha_on and self.first_word is None:\n                \n                # Find highest frequency word in the list and guess it\n                best_word = None\n                best_freq = 0\n                for word in self.first_candidates:\n                    if word in self.keyword_supply: # Ignore public KW\n                        continue\n                    if word in obs.guesses: # Ignore previous guesses\n                        continue\n                    if self.freq[word] > best_freq:\n                        best_freq = self.freq[word]\n                        best_word = word\n                if best_word is not None:\n                    return best_word\n                else:\n                    # We've already guessed all of the words, so start doing phrases using the most likely first word\n                    # Get most likely first word first\n                    # Still haven't proven the first word of the keyword yet, though\n\n                    print(\"Guessed all words, start doing phrases\")\n\n                    # Use the highest frequency candidate first word as the seed for enumerating noun phrases\n                    best_word = None\n                    best_freq = 0\n                    for word in self.first_candidates:\n                        if self.freq[word] > best_freq:\n                            best_freq = self.freq[word]\n                            best_word = word\n\n                    # Propose candidate noun phrases beginning with the most likely first word\n                    phrase_candidates = self.p.noun_phrases(best_word, self.tested_phrases).split(', ')\n                    if len(phrase_candidates) == 1:\n                        phrase_candidates = self.p.noun_phrases(best_word, self.tested_phrases).split(',')\n                    print(phrase_candidates)\n\n                    # Check validity of generated candidates\n                    for candidate in phrase_candidates:\n                        valid_c = self.valid_phrase(candidate, obs)\n                        print(valid_c)\n                        if valid_c is not None:\n                            print(\"Found phrase\")\n                            self.tested_phrases = self.tested_phrases + [valid_c]\n                            return valid_c # Return first valid choice\n\n            # If we run out of candidates during second word guessing\n            if self.alpha_on and self.first_word is not None:\n                \n                # Find highest frequency word in the list and guess its phrase\n                best_word = None\n                best_freq = 0\n                for word in self.second_candidates:\n                    phrase = self.first_word + ' ' + word\n                    if phrase in self.keyword_supply:\n                        continue\n                    if phrase in obs.guesses:\n                        continue\n                    if self.freq[word] > best_freq:\n                        best_freq = self.freq[word]\n                        best_word = phrase\n                if best_word is not None:\n                    return best_word\n                    \n                \n            # Code for \"THINGS\" ##########################################\n            \n            # Get known information about category, location, and size\n            pos_s, pos_p = self.tagman.get_positive_categories()\n            if len(pos_p) <= 1:\n                category = 'tangible objects'\n            if len(pos_p) < 2:\n                prior_category = 'things'\n            if len(pos_p) >= 2:\n                category = pos_p[-1]\n                prior_category = pos_p[-2]\n            location, _ = self.tagman.get_location()\n            if location is None:\n                location = ''\n            size, _ = self.tagman.get_size()\n            if size is None:\n                size = ''\n\n            # Material only used in precat mode\n            material, _ = self.tagman.get_material()\n\n            # Enumerate a list of ~30 candidate keywords based on known information\n            summary, _ = self.tagman.get_summary()\n            output = self.p.list_of_thirty_withsummary(category, prior_category, location, material, size, summary, 0.1, DEBUG)  \n\n            # Guess one of the things or locations, avoiding duplicates\n            entries = output.split(',')\n            if len(entries) == 0:\n                entries = ['(no guess)']\n            output = None\n            \n            # Identify guesses which haven't been guessed before\n            new_guesses = []\n            for entry in entries:\n                # print(entry + '\\n')\n                found = False\n                entry = strip_accents(entry.strip().lower())\n\n                # Fix a few misspellings or limitations of kaggle-supplied keyword list\n                if entry in self.corrections.keys():\n                    entry = self.corrections[entry]\n\n                # Do some validity checks\n                found = False\n                for a in obs.guesses:\n                    if entry.strip().lower() == a.strip().lower():\n                        print(f\"Skipping {entry.strip()}\\n\")\n                        found = True\n                    if KEYWORD_BIAS == 'exclude':\n                        if entry.strip().lower() in self.corrections.keys():\n                            entry_mod = self.corrections[entry.strip().lower()]\n                        else:\n                            entry_mod = entry\n                        if entry_mod in self.keyword_supply:\n                            print(f\"Skipping {entry.strip()}\\n\")\n                            found = True\n                if not found:\n                    new_guesses.append(entry.lower().strip())\n\n            # Code to bias toward keyword supply list [DISABLED in final submission]\n            print(f\"Keyword bias {KEYWORD_BIAS}\\n\")\n            if KEYWORD_BIAS == 'on': # Bias towards known keywords\n                # Find first new guess which is a known keyword\n                for guess in new_guesses:\n                    if guess.lower().strip() in self.corrections.keys():\n                        guess = self.corrections[guess]\n                    if guess.lower().strip() in self.keyword_supply:\n                        output = guess.lower().strip()\n                        return output\n\n            if output is None and len(new_guesses) > 0:\n                output = new_guesses[0]\n            else:\n                output = entries[0]\n\n        if output is not None:\n            return output\n        else:\n            return \"[No guess]\"\n       \n        \n        \n    def answerer(self, obs):\n           \n        if DEBUG:\n            print(\"ANSWERER:\\n\")\n        keyword = obs.keyword\n\n        # Debug code to override keyword for testing\n        if self.fixed_keyword is not None:\n            keyword = self.fixed_keyword\n\n        # Do some one-time analysis of the grammar of the keyword itself\n    \n        if \"proper name\" not in self.tagman.tags.keys():\n            # Is it a proper name?\n            proper_name = self.p.proper_name(keyword)\n            self.tagman.set_proper_name(proper_name)\n            if proper_name.lower() == 'no':\n                # Find the proper leading article\n                if keyword[0].lower() in ['a', 'e', 'i', 'o', 'u', 'h']:\n                    self.tagman.set_article(' an ')\n                else:\n                    self.tagman.set_article(' a ')\n\n            # plural = self.p.plural(keyword)    \n        \n        # Preface the keyword with an appropriate article\n        article, _ = self.tagman.get_article()\n        kw_plus_art = article + keyword + ' '\n            \n        category = obs.category # things or place\n        question = obs.questions[-1]\n\n        print(\"Keyword: \" + keyword + \"\\n\")\n\n\n        ############ Fixed pattern handler ##############\n        if question.lower() == 'is it agent alpha?': # Indicate that we are smart about alphabetical order\n            return 'yes'\n\n        # Very specific pattern match for agent alpha\n        if question.lower().find('Does the keyword (in lowercase) precede'.lower()) > -1 or question.lower().find('Does the keyword (in lowercase) come before'.lower()) > -1:\n            print(\"Alpha pattern match\\n\")\n            try:\n                testword = question.split('\"')[1].lower()\n                print(f\"Testword {testword}\")\n                if keyword.lower().strip() < testword.lower().strip():\n                    return 'yes'\n                else:\n                    return 'no'\n            except:\n                pass\n\n        # General pattern matching for other alpha-like agents\n\n        # if self.p.alpha_check(question, 0.6, DEBUG) == 'yes': # Other lexicographical ordering question\n        if 'lexicograph' in question.lower() or 'alphabetical' in question.lower() or 'sorting' in question.lower() or 'sort order' in question.lower():\n            # testword = self.p.alpha_extract_word(question, 0.1, DEBUG) # Find the test word or letter\n            print(\"Testing alphabetical order\\n\")\n            m = re.findall(\"['\\\"].*['\\\"]\", question.lower()) # Extract everything in quotes\n            if len(m) > 0:\n                testword = m[0][1:-1] # Strip the quotes\n                print(f\"Testword: {testword}\\n\")\n                \n                if question.lower().find(testword.lower()) > 0:                    \n                    if 'before' in question.lower():\n                        early_late = 'earlier'\n                    elif 'earlier' in question.lower():\n                        early_late = 'earlier'\n                    elif 'after' in question.lower():\n                        early_late = 'later'\n                    elif 'smaller' in question.lower():\n                        early_late = 'earlier'\n                    elif 'precede' in question.lower():\n                        early_late = 'earlier'\n                    elif 'larger' in question.lower():\n                        early_late = 'later'\n                    elif 'lower' in question.lower():\n                        print('here')\n                        early_late = 'earlier'\n                    elif 'higher' in question.lower():\n                        early_late = 'later'\n                    else:\n                        early_late = self.p.alpha_earlier_later(question, test_word, 0.6, DEBUG)\n                    response = None\n                    if early_late.lower() == 'earlier':\n                        response = keyword.lower().strip() < testword.lower().strip()\n                    elif early_late.lower() == 'later':\n                        response = keyword.lower().strip() > testword.lower().strip()\n                    if response is not None:\n                        if response:\n                            return 'yes'\n                        else:\n                            return 'no'\n\n        # Now see if we're looking at start letter or containing letters\n        #if self.p.alpha_container_check(question, 0.6, DEBUG).lower() == 'yes':\n        if ' letter ' in question.lower() or ' letters ' in question.lower() or ' letter:' in question.lower() or ' letters:' in question.lower() or ' letter?' in question.lower() or ' letters?' in question.lower():\n            print(\"Regex match try\\n\")\n            # testletters = self.p.alpha_extract_letters(question, 0.6, DEBUG).split(',')\n            m = re.findall(\"['\\\"][a-z]*['\\\"]\", question.lower()) # Extract everything in quotes\n            if len(m) > 0:\n                testletters = []\n                for entry in m:\n                    testletters.append(entry[1:-1])\n            else:\n                # Automatically extract the candidate letter list\n                testletters = self.p.alpha_extract_letters(question, 0.6, DEBUG).split(',')\n            if len(testletters) <= 25: # Sanity check\n                start = None\n                if 'includes' in question.lower():\n                    begins_contains = 'contains'\n                else:\n                    # Determine if it is a \"begins\" or \"contains\" question\n                    begins_contains = self.p.alpha_begins_contains(question, 0.6, DEBUG)\n                    \n                if begins_contains == 'begins':\n                    start = True\n                elif begins_contains == 'contains':\n                    start = False    \n                if start is not None:\n                    for letter in testletters:\n                        if start:\n                            if letter.lower().strip() == keyword.lower().strip()[0]:\n                                return 'yes'\n                        else:\n                            if letter.lower().strip() in keyword.lower().strip():\n                                return 'yes'\n                    return 'no' # Return no if not found\n\n        # Now check if we're just confirming whether keyword is included in an explcit list or not\n        # if self.p.alpha_explicit_list(question, 0.6, DEBUG).lower() == 'yes':\n        test_phrases = ['keyword one of the following', 'is the thing precisely any of', 'keyword in the following']\n        for phrase in test_phrases:\n            if phrase.lower() in question.lower():\n                print(\"List match\\n\")\n                m = re.findall(\"['\\\"][a-z]*['\\\"]\", question.lower()) # Extract everything in quotes\n                if len(m) > 0:\n                    list_contents = m\n                else:\n                    list_contents = self.p.alpha_extract_list(question, 0.6, DEBUG).split(',')\n                print(f\"List contents: {list_contents}\\n\")\n                \n                for item in list_contents:\n                    if keyword.lower().strip() == item.lower().strip():\n                        return 'yes'\n                return 'no'\n\n        # End Alpha handler #####################\n        \n\n        # Replace subject of the sentence with the keyword - big improvement in answer quality\n        if 'keyword' in question.lower(): # Replace \"keyword\" with the actual keyword, if present in the question\n            while 'keyword' in question.lower():\n                for phrase in ['the keyword', 'keyword']:\n                    while phrase in question.lower():\n                        idx = question.lower().find(phrase)\n                        if idx == -1:\n                            break\n                        new_q = ''\n                        if idx > 0:\n                            new_q += question[:idx]\n                        new_q += kw_plus_art + question[idx+len(phrase):]\n                        question = new_q\n        else:\n            # Find the actual subject word based on LLM assessment of the subject\n            subject = ' ' + self.p.subject(question).strip() + ' '\n            if question.lower().find(subject.lower()) > 0: # Found a subject\n                for precedent in [' the ', ' a ', ' an ', '']:\n                    phrase = precedent + subject.lower()\n                    for i in range(0, 3):\n                        if subject.lower() not in question.lower():\n                            break                        \n                        idx = question.lower().find(phrase)\n                        if idx == -1:\n                            break\n                        new_q = ''\n                        if idx > 0:\n                            new_q += question[:idx] + \" \"\n                        new_q += kw_plus_art.strip() + \" \" + question[idx+len(phrase):].strip()\n                        question = new_q\n            else:               \n                # Default, risky, behavior\n                # It once rephrased \"Did a cantaloupe write 'Pride and Prejudice'?\" to \"Did Jane Austen, not a cantaloupe, write 'Pride and Prejudice'?\" :)\n                question = self.p.rephrase_with_kw(question, keyword, 0.1, DEBUG)\n                \n        # Answer the question\n        output = self.p.answer_question(question , 0.1, DEBUG)\n\n        return output       \n    \n    \nrobot = Robot(FIXED_KEYWORD)\n\n########################\n# Testing code\n########################\n\ndef dumbo(obs, cfg):\n    return \"yes\"\n\n# Test code for alpha agent\ndef dumbo_alpha(obs, cfg):\n    # Asks alpha related questions\n    if obs.turnType == 'ask':\n        test_type = random.choice(('starts', 'contains', 'list', 'alpha'))\n        letters = []\n        count = random.choice((1, 2, 3))\n        alpha = random.choice(('bird', 'llama', 'zebra', 'washington dca'))\n        wordlist = \"'bird', 'monkey', 'digeroo'\"\n        for i in range(0,count):\n            letters.append(random.choice(('a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z')))\n        letter_str = f\"'{letters[0]}'\"\n        if len(letters) > 1:\n            add_str = \"', '\".join(letters)\n            letter_str = f\"'{add_str}'\"\n            \n        if test_type == 'starts':\n            output = f\"Does the keyword begin with any of these letters: {letter_str}?\"\n        if test_type == 'contains':\n            output = f\"Does the keyword contain any of these letters: {letter_str}?\"\n        if test_type == 'list':\n            output = f\"Is the keyword in the following list: {wordlist}?\"\n        if test_type == 'alpha':\n            output = f\"Is the keyword lexicographically smaller than \\\"{alpha}\\\"?\"\n        print(output +'\\n')\n        return output\n            \n    if obs.turnType == 'guess':\n        return 'random guess'\n\ndef one_round(env):\n    if env.state[0].status == \"ACTIVE\":\n        agent1_action = agent(env.state[0].observation, CFG)\n    else:\n        agent1_action = ''\n        \n    if env.state[1].status == \"ACTIVE\":\n        agent2_action = agent(env.state[1].observation, CFG)\n    else:\n        agent2_action = ''\n    \n    if env.state[2].status == \"ACTIVE\":\n        agent3_action = dumbo(env.state[2].observation, CFG)\n    else:\n        agent3_action = ''\n    \n    if env.state[3].status == \"ACTIVE\":\n        agent4_action = dumbo(env.state[3].observation, CFG)\n    else:\n        agent4_action = ''\n    state = env.step([agent1_action, agent2_action, agent3_action, agent4_action])\n\nimport statistics\n\n# Run batch evaluation for a word list\ndef eval(wordlist, kw_list=None):\n    from kaggle_environments import make\n    success_count = 0\n    for word in wordlist:   \n        rounds = 0\n        env = make(\"llm_20_questions\", debug=True)\n        env.reset()\n        robot.reset(word)\n        print(robot.tagman.tags)\n        if kw_list is not None:\n            robot.keyword_supply = [x for x in kw_list]\n        print(robot.keyword_supply)\n        round_wins = []\n        while(True):\n            try:\n                rounds += 1\n                one_round(env)\n                if len(env.state[1]['observation']['guesses']) > 0 and compare_words(env.state[1]['observation']['guesses'][-1], word):\n                    success_count += 1\n                    print(\"\\n******SUCCESS*******\\n\")\n                    break\n            except Exception as e:\n                print(\"\\n+++++++++FAILURE++++++++\\n\")\n                # raise e\n                break\n        round_wins.append(rounds)\n        # env.reset()\n    print(f\"\\nOverall success rate: {success_count / len(wordlist)}\")\n    print(f\"\\nOverall avg rounds: {statistics.mean(round_wins)}\")\n\n    \n# Main calling function for the agent\ndef agent(obs, cfg):    \n    if obs.turnType ==\"ask\":\n        response = robot.on(mode = \"asking\", obs = obs) \n        if len(response) > 750:\n            response = response[:750]\n    elif obs.turnType ==\"guess\":\n        response = robot.on(mode = \"guessing\", obs = obs)    \n        if len(response) > 100:\n            response = response[:100]\n    elif obs.turnType ==\"answer\":\n        response = robot.on(mode = \"answering\", obs = obs)  \n        if response.lower() != 'yes' and response.lower() != 'no':\n            response = 'no'\n    if response == None or len(response)<=1:\n        response = \"no\"        \n    return response\n","metadata":{"execution":{"iopub.status.busy":"2024-07-25T23:14:00.114911Z","iopub.execute_input":"2024-07-25T23:14:00.115323Z","iopub.status.idle":"2024-07-25T23:14:28.892520Z","shell.execute_reply.started":"2024-07-25T23:14:00.115276Z","shell.execute_reply":"2024-07-25T23:14:28.890931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from importlib.metadata import version\nversion(\"numpy\")","metadata":{"execution":{"iopub.status.busy":"2024-07-23T14:15:47.935601Z","iopub.execute_input":"2024-07-23T14:15:47.935989Z","iopub.status.idle":"2024-07-23T14:15:47.950397Z","shell.execute_reply.started":"2024-07-23T14:15:47.935961Z","shell.execute_reply":"2024-07-23T14:15:47.949187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!apt install pigz pv > /dev/null","metadata":{"execution":{"iopub.status.busy":"2024-07-23T12:57:29.500682Z","iopub.status.idle":"2024-07-23T12:57:29.501038Z","shell.execute_reply.started":"2024-07-23T12:57:29.500844Z","shell.execute_reply":"2024-07-23T12:57:29.500877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !tar --use-compress-program='pigz --fast --recursive | pv' -cf submission.tar.gz -C /kaggle/input/llama-3/transformers/8b-chat-hf . -C /kaggle/working/submission . -C /kaggle/tmp/ .\n!tar --use-compress-program='pigz --fast --recursive | pv' -cf submission.tar.gz -C /kaggle/working/submission . -C /kaggle/tmp/ .","metadata":{"execution":{"iopub.status.busy":"2024-07-23T12:57:29.502345Z","iopub.status.idle":"2024-07-23T12:57:29.502664Z","shell.execute_reply.started":"2024-07-23T12:57:29.502506Z","shell.execute_reply":"2024-07-23T12:57:29.502519Z"},"trusted":true},"execution_count":null,"outputs":[]}]}